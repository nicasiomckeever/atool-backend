"""
Job Worker with Supabase Realtime WebSocket
Replaces polling with instant push notifications
"""

import os
import sys
import time
import base64
import asyncio
import threading
import requests
import logging
from dotenv import load_dotenv
from modal_url_manager import get_modal_url_manager

# Fix Windows console encoding for emoji support
if sys.platform == "win32":
    try:
        import codecs
        sys.stdout = codecs.getwriter("utf-8")(sys.stdout.detach())
        sys.stderr = codecs.getwriter("utf-8")(sys.stderr.detach())
    except Exception:
        pass  # Ignore if encoding setup fails

# Suppress noisy websocket errors during keepalive timeout (expected behavior)
# These errors occur when connection times out during long-running jobs
# Our auto-reconnection logic handles this gracefully
logging.getLogger('websockets').setLevel(logging.CRITICAL)
logging.getLogger('websockets.protocol').setLevel(logging.CRITICAL)
logging.getLogger('realtime').setLevel(logging.WARNING)
logging.getLogger('root').setLevel(logging.WARNING)

# Load environment variables
load_dotenv()

# Use internal worker URL for container-to-container communication
BACKEND_URL = os.getenv("WORKER_BACKEND_URL") or os.getenv("BACKEND_URL", "http://localhost:5000")
SUPABASE_URL = os.getenv("SUPABASE_URL")
# CRITICAL: Worker needs SERVICE_ROLE_KEY for Realtime subscriptions (anon key gets 401)
SUPABASE_KEY = os.getenv("SUPABASE_SERVICE_ROLE_KEY") or os.getenv("SUPABASE_ANON_KEY")

# SSL Certificate Verification (disable for self-signed certs)
VERIFY_SSL = os.getenv("VERIFY_SSL", "False").lower() == "true"

print("=" * 60)
print("ğŸ¤– JOB WORKER STARTING (REALTIME MODE)")
print("=" * 60)
print(f"ğŸ“¡ Backend URL (external): {os.getenv('BACKEND_URL', 'NOT SET')}")
print(f"ğŸ“¡ Worker Backend URL (internal): {os.getenv('WORKER_BACKEND_URL', 'NOT SET')}")
print(f"ğŸ“¡ Using: {BACKEND_URL}")
print(f"ğŸ”— Supabase URL: {SUPABASE_URL}")
print("=" * 60)
print()
sys.stdout.flush()  # Force flush output immediately

def get_comfyui_url():
    """Fetch ComfyUI URL from backend (Modal URL from Discord)"""
    try:
        response = requests.get(f"{BACKEND_URL}/get-url", timeout=10, verify=VERIFY_SSL)
        if response.status_code == 200:
            data = response.json()
            if data.get("success") and data.get("url"):
                url = data["url"]
                print(f"âœ… ComfyUI URL: {url}")
                return url
        return None
    except Exception as e:
        print(f"âŒ Error fetching ComfyUI URL: {e}")
        return None

def on_new_job(payload):
    """Callback when new job is created via realtime"""
    try:
        print()
        print("ğŸ”” REALTIME EVENT RECEIVED!")
        print(f"Payload: {payload}")
        
        # Extract job data from payload
        record = payload.get("record") or payload.get("new") or payload
        
        if not record:
            print("âš ï¸ No record in payload")
            return
        
        # Only process pending jobs
        if record.get("status") != "pending":
            print(f"â­ï¸ Skipping job with status: {record.get('status')}")
            return
        
        job_id = record.get("job_id") or record.get("id")
        
        # Get priority from metadata
        metadata = record.get("metadata", {})
        priority = metadata.get("priority", "N/A")
        priority_emoji = {1: "ğŸ”µ", 2: "ğŸŸ¡", 3: "ğŸŸ "}.get(priority, "âšª")
        
        print()
        print("=" * 60)
        print(f"ğŸ“‹ NEW JOB (REALTIME): {job_id}")
        print("=" * 60)
        print(f"ğŸ‘¤ User: {record.get('user_id')}")
        print(f"ğŸ“ Prompt: {record.get('prompt')}")
        print(f"ğŸ¤– Model: {record.get('model')}")
        print(f"ğŸ“ Aspect Ratio: {record.get('aspect_ratio')}")
        print(f"{priority_emoji} Priority: {priority}")
        print("=" * 60)
        print()
        
        # Make sure Modal is awake
        print(f"ğŸ“‹ Ensuring Modal is awake...")
        comfyui_url = get_comfyui_url()
        if not comfyui_url:
            print(f"âš ï¸ Could not get Modal URL, skipping job...")
            return
        
        # Process the job
        process_job(record, comfyui_url)
        
    except Exception as e:
        print(f"âŒ Error in realtime callback: {e}")
        import traceback
        traceback.print_exc()


def process_job(job, comfyui_url=None):
    """Process a job by calling ComfyUI API or Video API with HYBRID ROUTING"""
    job_id = job.get("job_id") or job.get("id")
    job_type = job.get("job_type", "image")  # Default to image if not specified
    
    # Detect video jobs by model name if job_type not specified
    model = job.get("model", "")
    # Support both LTX-Video and Wan2.2 (Wan2.2 uses ComfyUI workflows)
    video_models = ["ltx-video-13b", "ltx-video", "wan22-animate-14b", "wan2.2", "wan"]
    
    if job_type == "image" and any(vm in model.lower() for vm in video_models):
        job_type = "video"
        print(f"ğŸ” Detected VIDEO job based on model: {model}")
    
    print(f"\n{'='*60}")
    print(f"ğŸ¨ HYBRID ROUTING: {job_type.upper()} generation")
    print(f"{'='*60}")
    
    # HYBRID ROUTING: Get appropriate endpoint URL based on job type
    manager = get_modal_url_manager()
    endpoint_url = manager.get_endpoint_url(job_type)
    
    if not endpoint_url:
        print(f"âŒ Could not get {job_type} endpoint URL")
        return
    
    print(f"ğŸ“¡ Using endpoint: {endpoint_url}")
    print(f"ğŸ¯ Job ID: {job_id}")
    print(f"{'='*60}\n")
    
    # Route to appropriate handler based on job type
    if job_type == "video":
        return process_video_job(job, endpoint_url)
    else:
        return process_image_job(job, endpoint_url)


def process_video_job(job, base_url):
    """Process a video generation job via unified /generate endpoint"""
    job_id = job.get("job_id") or job.get("id")
    
    print(f"\n{'='*70}")
    print(f"ğŸ¬ PROCESSING VIDEO JOB")
    print(f"{'='*70}")
    print(f"ğŸ“‹ Job ID: {job_id}")
    print(f"ğŸ‘¤ User ID: {job.get('user_id', 'N/A')}")
    print(f"ğŸ“ Prompt: {job.get('prompt', 'N/A')}")
    print(f"ğŸ¤– Model: {job.get('model', 'N/A')}")
    print(f"ğŸ“ Aspect Ratio: {job.get('aspect_ratio', '16:9')}")
    print(f"ğŸ”— Modal Endpoint: {base_url}")
    print(f"{'='*70}\n")
    sys.stdout.flush()
    
    # Track the current URL in the manager for proper expiry handling
    url_manager = get_modal_url_manager()
    url_manager.current_url = base_url
    
    try:
        # Update job status to running
        requests.post(
            f"{BACKEND_URL}/worker/job/{job_id}/progress",
            json={
                "progress": 10,
                "message": "Starting video generation..."
            },
            timeout=10
        )
        
        # Use unified API on the main endpoint (/generate with type: "video")
        video_api_url = base_url
        
        # Check for input image URL and duration in job metadata
        metadata = job.get("metadata", {})
        print(f"ğŸ“¦ Job metadata: {metadata}")
        input_image_url = metadata.get("input_image_url")
        duration = metadata.get("duration", 5)  # Default to 5 seconds
        print(f"â±ï¸  Duration from metadata: {duration} seconds")
        
        # AUTO-DETECT: Determine if i2v or t2v based on image presence
        job_model = job.get("model", "wan2.2_t2v_high_noise_14B_fp8_scaled.safetensors")
        
        # Override model based on image presence (use exact Modal API filenames)
        if input_image_url:
            # Image provided -> use image-to-video model and workflow
            actual_model = "wan2.2_i2v_high_noise_14B_fp16.safetensors"
            workflow_type = "image-to-video"
            print(f"ğŸ–¼ï¸  AUTO-DETECTED: Image-to-Video mode")
            print(f"   Input image: {input_image_url}")
        else:
            # No image -> use text-to-video model and workflow
            actual_model = "wan2.2_t2v_high_noise_14B_fp8_scaled.safetensors"
            workflow_type = "text-to-video"
            print(f"ğŸ“ AUTO-DETECTED: Text-to-Video mode")
        
        print(f"ğŸ¤– Model: {actual_model} (Original: {job_model})")
        print(f"ğŸ¬ Workflow: {workflow_type}")
        print(f"â±ï¸  Duration: {duration} seconds")
        
        # Map aspect ratio to WAN 2.2 supported resolutions
        aspect_ratio = job.get("aspect_ratio", "16:9")
        aspect_ratio_map = {
            "16:9": (1024, 576),   # Landscape
            "1:1": (768, 768),      # Square
            "9:16": (576, 1024),    # Portrait
        }
        width, height = aspect_ratio_map.get(aspect_ratio, (1024, 576))  # Default to 16:9
        print(f"ğŸ“ Aspect Ratio: {aspect_ratio} â†’ {width}x{height}")
        
        # Prepare unified generation payload
        payload = {
            "type": "video",
            "prompt": job.get("prompt"),
            "model": actual_model,  # Use auto-detected model
            "workflow_type": workflow_type,  # Pass workflow type to API
            "width": width,
            "height": height,
            "duration": duration,  # Pass duration to unified API
            "fps": 25,  # 25 fps for faster generation
        }
        
        # Add input image URL if available (for image-to-video)
        if input_image_url:
            payload["input_image_url"] = input_image_url
        
        print(f"ğŸ“¤ Sending video generation request to {video_api_url}/generate")
        print(f"ğŸ“¦ Payload: {payload}")
        print(f"â±ï¸  Timeout: 1800 seconds (30 minutes)")
        
        # Call video API (longer timeout for video generation)
        response = requests.post(
            f"{video_api_url}/generate",
            json=payload,
            timeout=1800  # 30 minutes for video generation
        )
        
        print(f"ğŸ“¥ Response status: {response.status_code}")
        print(f"ğŸ“„ Response headers: {dict(response.headers)}")
        
        if response.status_code != 200:
            # Try to get error details
            try:
                error_data = response.json()
                error_msg = error_data.get("error", response.text)
            except:
                error_msg = response.text
            raise Exception(f"Video API returned status {response.status_code}: {error_msg}")
        
        # Update progress
        requests.post(
            f"{BACKEND_URL}/worker/job/{job_id}/progress",
            json={
                "progress": 50,
                "message": "Video generated, uploading..."
            },
            timeout=10
        )
        
        # Save video file temporarily
        import tempfile
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp_file:
            tmp_file.write(response.content)
            video_path = tmp_file.name
        
        print(f"ğŸ’¾ Video saved temporarily to: {video_path}")
        
        # Upload to Cloudinary
        print(f"â˜ï¸  Uploading video to Cloudinary...")
        from cloudinary_manager import get_cloudinary_manager
        cloudinary = get_cloudinary_manager()
        
        video_url = cloudinary.upload_video(video_path, job_id)
        print(f"âœ… Video uploaded: {video_url}")
        
        # Clean up temp file
        import os as os_module
        os_module.unlink(video_path)
        
        # Mark job as completed with video URL (use image_url field for compatibility)
        requests.post(
            f"{BACKEND_URL}/worker/job/{job_id}/complete",
            json={
                "image_url": video_url,  # Backend expects image_url field
                "video_url": video_url,  # Also include for clarity
                "success": True
            },
            timeout=10
        )
        
        print(f"âœ… Video job {job_id} completed successfully!")
        
    except Exception as e:
        error_message = str(e)
        print(f"âŒ Error processing video job: {error_message}")
        
        # Check if it's a rate limit error
        url_manager = get_modal_url_manager()
        
        # Debug: Show what we're checking
        print(f"[DEBUG] Checking if error should trigger URL expiry...")
        print(f"[DEBUG] Error message (lowercase): {error_message.lower()}")
        
        is_expiry_error = url_manager.is_limit_reached_error(error_message)
        print(f"[DEBUG] is_limit_reached_error() returned: {is_expiry_error}")
        
        if is_expiry_error:
            print("[ALERT] Modal deployment should be marked inactive (stopped/limit/error)!")
            print(f"[ACTION] Current deployment ID: {url_manager.current_deployment_id}")
            print("[ACTION] Marking current deployment as inactive in database...")
            
            success = url_manager.mark_deployment_inactive()
            print(f"[ACTION] Mark inactive result: {success}")
            
            # Invalidate the cache in app.py so it fetches fresh URL
            if success:
                print("[ACTION] Invalidating app.py cache...")
                try:
                    invalidate_response = requests.post(
                        f"{BACKEND_URL}/invalidate-cache",
                        timeout=5
                    )
                    if invalidate_response.status_code == 200:
                        print("[OK] Cache invalidation triggered successfully")
                    else:
                        print(f"[WARN] Cache invalidation returned {invalidate_response.status_code}")
                except Exception as cache_err:
                    print(f"[WARN] Failed to invalidate cache: {cache_err}")
            
            print("[ACTION] Getting next active deployment...")
            next_deployment = url_manager.get_active_deployment()
            if next_deployment:
                print(f"[OK] Next deployment ready: #{next_deployment['deployment_number']}")
                print("[INFO] Retrying ALL pending jobs with new deployment...")
                
                # STEP 3: URL Rotation Recovery - retry all pending jobs
                retry_all_pending_jobs()
            else:
                print("[ERROR] No active deployments available!")
            
            # DO NOT mark job as failed - leave it pending for retry
            print("[TERMINATE] Terminating current task without marking complete")
            print("[INFO] Job status remains unchanged for automatic retry")
            return
        else:
            print("[DEBUG] Error does not match expiry patterns, not rotating URL")
        
        # DO NOT mark job as failed for ANY error - leave it pending for retry
        print("[TERMINATE] Terminating current task without marking as failed")
        print("[INFO] Job remains in pending status for automatic retry")
        print(f"[DEBUG] Error was: {error_message}")
        return


def process_image_job(job, comfyui_url):
    """Process an image generation job"""
    job_id = job.get("job_id") or job.get("id")
    
    print(f"\n{'='*70}")
    print(f"ğŸ¨ PROCESSING IMAGE JOB")
    print(f"{'='*70}")
    print(f"ğŸ“‹ Job ID: {job_id}")
    print(f"ğŸ‘¤ User ID: {job.get('user_id', 'N/A')}")
    print(f"ğŸ“ Prompt: {job.get('prompt', 'N/A')}")
    print(f"ğŸ¤– Model: {job.get('model', 'N/A')}")
    print(f"ğŸ“ Aspect Ratio: {job.get('aspect_ratio', '1:1')}")
    print(f"ğŸš« Negative Prompt: {job.get('negative_prompt', 'N/A')}")
    print(f"ğŸ”— Modal Endpoint: {comfyui_url}")
    print(f"{'='*70}\n")
    sys.stdout.flush()  # Force immediate output on Windows
    
    # Track the current URL in the manager for proper expiry handling
    url_manager = get_modal_url_manager()
    url_manager.current_url = comfyui_url
    
    try:
        # Update job status to running
        requests.post(
            f"{BACKEND_URL}/worker/job/{job_id}/progress",
            json={
                "progress": 10,
                "message": "Starting generation..."
            },
            timeout=10
        )
        
        # Debug: Log all job fields
        print(f"ğŸ” Job object fields:")
        print(f"   Available: {list(job.keys())}")
        for key, value in job.items():
            if key == "metadata":
                print(f"   {key}: {value}")
            elif key not in ["prompt", "negative_prompt"]:  # Skip long fields
                print(f"   {key}: {value}")
        
        # Prepare payload
        model_name = job.get("model", "openflux1-v0.1.0-fp8.safetensors")
        metadata = job.get("metadata", {}) or {}
        input_image_url = metadata.get("input_image_url") or job.get("image_url")
        is_qwen = isinstance(model_name, str) and ("qwen" in model_name.lower())

        payload = {
            "prompt": job.get("prompt"),
            "aspect_ratio": job.get("aspect_ratio", "1:1"),
            "model": model_name  # Default to provided model
        }

        # Debug: Log what we found
        print(f"ğŸ” Image job processing:")
        print(f"   Model: {model_name}")
        print(f"   Is Qwen: {is_qwen}")
        print(f"   Metadata: {metadata}")
        print(f"   job.get('image_url'): {job.get('image_url')}")
        print(f"   Input Image URL: {input_image_url}")

        # Qwen Image Edit support: require input_image_url and provide sensible defaults
        if is_qwen:
            payload["input_image_url"] = input_image_url
            payload["steps"] = 20
            payload["cfg"] = 2.5
            # Special flag for Qwen workflow
            payload["is_qwen"] = True
            payload["qwen_model"] = "qwen_image_edit_fp8_e4m3fn.safetensors"
            payload["qwen_vae"] = "qwen_image_vae.safetensors"
            payload["qwen_text_encoder"] = "qwen_2.5_vl_7b_fp8_scaled.safetensors"
            print(f"ğŸ–¼ï¸  Qwen Image Edit detected, using input image: {input_image_url}")
            print(f"   Qwen Model: {payload['qwen_model']}")
            print(f"   Qwen VAE: {payload['qwen_vae']}")
            print(f"   Qwen Text Encoder: {payload['qwen_text_encoder']}")
        
        print(f"ğŸ“¤ Sending generation request to {comfyui_url}/generate")
        print(f"ğŸ“¦ Payload:")
        for key, value in payload.items():
            if key == "prompt" and len(str(value)) > 100:
                print(f"   {key}: {str(value)[:100]}...")
            else:
                print(f"   {key}: {value}")
        print(f"â±ï¸  Timeout: 300 seconds (5 minutes)")
        print()
        sys.stdout.flush()
        
        # Retry logic for Modal cold start
        max_retries = 3
        retry_delay = 10  # Start with 10 seconds
        response = None
        
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    print(f"ğŸ”„ Retry attempt {attempt + 1}/{max_retries} after {retry_delay}s...")
                    time.sleep(retry_delay)
                
                print(f"â³ Sending request to Modal...")
                sys.stdout.flush()
                
                response = requests.post(
                    f"{comfyui_url}/generate",
                    json=payload,
                    timeout=300  # 5 minutes timeout for generation
                )
                
                print(f"ğŸ“¥ Response received! Status: {response.status_code}")
                print(f"ğŸ“„ Response headers: {dict(response.headers)}")
                sys.stdout.flush()
                
                content_type = response.headers.get('Content-Type', '')
                print(f"ğŸ“‹ Content-Type: {content_type}")
                
                # Check for Modal stopped error (404)
                if response.status_code == 404 and "app for invoked web endpoint is stopped" in response.text:
                    if attempt < max_retries - 1:
                        print(f"âš ï¸  Modal is stopped, triggering cold start (takes ~30-60s)...")
                        retry_delay = 30  # Wait longer for cold start
                        continue
                    else:
                        raise Exception("Modal failed to start after multiple retries")
                
                # Success or other error - break retry loop
                break
                
            except requests.exceptions.Timeout:
                if attempt < max_retries - 1:
                    print(f"â±ï¸  Request timed out, retrying...")
                    retry_delay = 30
                    continue
                raise Exception("Request timed out after 5 minutes")
            except requests.exceptions.ConnectionError as e:
                if attempt < max_retries - 1:
                    print(f"ğŸ”Œ Connection error, retrying... ({e})")
                    retry_delay = 20
                    continue
                raise Exception(f"Connection error: {e}")
            except Exception as e:
                if attempt < max_retries - 1:
                    print(f"âŒ Request failed, retrying... ({e})")
                    retry_delay = 15
                    continue
                raise Exception(f"Request failed: {e}")
        
        if response.status_code != 200:
            raise Exception(f"ComfyUI returned {response.status_code}: {response.text}")
        
        if response.status_code == 200:
            # Check if response is image or JSON
            content_type = response.headers.get("Content-Type", "")
            print(f"ğŸ“‹ Content-Type: {content_type}")
            
            if "image" in content_type:
                # Got image directly
                image_data = response.content
                print(f"ğŸ–¼ï¸ Received image directly ({len(image_data)} bytes)")
                
                # Prepare metadata for Cloudinary
                metadata = {
                    "prompt": job.get("prompt", ""),
                    "model": job.get("model", ""),
                    "aspect_ratio": job.get("aspect_ratio", ""),
                    "job_id": job_id,
                    "user_id": job.get("user_id", "")
                }
                
                print(f"ğŸ“‹ Metadata to upload:")
                for key, value in metadata.items():
                    print(f"   {key}: '{value}' (type: {type(value).__name__})")
                
                # Upload to Cloudinary with metadata
                print(f"\n{'='*70}")
                print(f"â˜ï¸  UPLOADING TO CLOUDINARY")
                print(f"{'='*70}")
                print(f"ğŸ“ File name: job_{job_id}.png")
                print(f"ğŸ“ Image size: {len(image_data)} bytes ({len(image_data)/1024:.1f} KB)")
                print(f"â±ï¸  Uploading...")
                sys.stdout.flush()
                
                upload_response = requests.post(
                    f"{BACKEND_URL}/cloudinary/upload-image",
                    json={
                        "image_data": base64.b64encode(image_data).decode('utf-8'),
                        "file_name": f"job_{job_id}.png",
                        "metadata": metadata
                    },
                    timeout=60
                )
                print(f"{'='*70}\n")
                sys.stdout.flush()
                
                if upload_response.status_code == 200:
                    cloudinary_data = upload_response.json()
                    image_url = cloudinary_data.get('secure_url')
                    cloudinary_link = cloudinary_data.get('secure_url')
                    
                    print(f"\n{'='*70}")
                    print(f"âœ… CLOUDINARY UPLOAD SUCCESSFUL!")
                    print(f"{'='*70}")
                    print(f"ğŸ”— URL: {cloudinary_link}")
                    print(f"{'='*70}\n")
                    sys.stdout.flush()
                    
                    # Mark job as complete
                    print(f"ğŸ’¾ Marking job as complete in database...")
                    sys.stdout.flush()
                    
                    complete_response = requests.post(
                        f"{BACKEND_URL}/worker/job/{job_id}/complete",
                        json={
                            "image_url": cloudinary_link or image_url,
                            "thumbnail_url": image_url
                        },
                        timeout=10
                    )
                    
                    if complete_response.status_code == 200:
                        print(f"\n{'='*70}")
                        print(f"ğŸ‰ JOB COMPLETED SUCCESSFULLY!")
                        print(f"{'='*70}")
                        print(f"ğŸ“‹ Job ID: {job_id}")
                        print(f"ğŸ–¼ï¸  Image URL: {cloudinary_link}")
                        print(f"â±ï¸  Total time: Complete")
                        print(f"{'='*70}\n")
                        sys.stdout.flush()
                    else:
                        print(f"âš ï¸  Failed to mark job complete: {complete_response.status_code}")
                        sys.stdout.flush()
                    
                    print()
                else:
                    raise Exception(f"Cloudinary upload failed: {upload_response.status_code} - {upload_response.text}")
            else:
                # JSON response with URL - need to download and upload to Cloudinary
                print(f"ğŸ“ Response is JSON")
                data = response.json()
                
                if not data.get("success"):
                    raise Exception(data.get("error", "Unknown generation error"))
                
                temp_image_url = data.get("image_url") or data.get("url")
                cloudinary_link = data.get("cloudinary_link")
                
                print(f"âœ… Generation complete!")
                print(f"ğŸ”— Temporary Image URL: {temp_image_url}")
                
                # If no Cloudinary link, download image and upload to Cloudinary
                if not cloudinary_link and temp_image_url:
                    print(f"ğŸ“¥ Downloading image from temporary URL...")
                    try:
                        img_response = requests.get(temp_image_url, timeout=30)
                        if img_response.status_code == 200:
                            image_data = img_response.content
                            print(f"âœ… Downloaded image ({len(image_data)} bytes)")
                            
                            # Prepare metadata
                            metadata = {
                                "prompt": job.get("prompt", ""),
                                "model": job.get("model", ""),
                                "aspect_ratio": job.get("aspect_ratio", ""),
                                "job_id": job_id,
                                "user_id": job.get("user_id", "")
                            }
                            
                            # Upload to Cloudinary
                            print(f"â˜ï¸  Uploading to Cloudinary...")
                            upload_response = requests.post(
                                f"{BACKEND_URL}/cloudinary/upload-image",
                                json={
                                    "image_data": base64.b64encode(image_data).decode('utf-8'),
                                    "file_name": f"job_{job_id}.png",
                                    "metadata": metadata
                                },
                                timeout=60
                            )
                            
                            if upload_response.status_code == 200:
                                cloudinary_data = upload_response.json()
                                cloudinary_link = cloudinary_data.get('secure_url')
                                print(f"âœ… Uploaded to Cloudinary: {cloudinary_link}")
                            else:
                                print(f"âš ï¸  Cloudinary upload failed: {upload_response.status_code}")
                                print(f"   Will use temporary URL as fallback")
                        else:
                            print(f"âš ï¸  Failed to download image: {img_response.status_code}")
                    except Exception as download_err:
                        print(f"âš ï¸  Error downloading/uploading image: {download_err}")
                        print(f"   Will use temporary URL as fallback")
                
                if cloudinary_link:
                    print(f"â˜ï¸  Final Cloudinary Link: {cloudinary_link}")
                
                # Mark job as complete with Cloudinary URL (or fallback to temp URL)
                final_url = cloudinary_link or temp_image_url
                print(f"ğŸ’¾ Saving to database: {final_url}")
                
                complete_response = requests.post(
                    f"{BACKEND_URL}/worker/job/{job_id}/complete",
                    json={
                        "image_url": final_url,
                        "thumbnail_url": final_url
                    },
                    timeout=10
                )
                
                if complete_response.status_code == 200:
                    print(f"âœ… Job {job_id} marked as complete!")
                else:
                    print(f"âš ï¸  Failed to mark job complete: {complete_response.status_code}")
                
                print()
        else:
            raise Exception(f"ComfyUI returned {response.status_code}: {response.text}")
            
    except Exception as e:
        error_message = str(e)
        print(f"âŒ Error processing image job: {error_message}")
        
        # Check if it's a deployment error (rate limit, stopped endpoint, etc.)
        url_manager = get_modal_url_manager()
        if url_manager.is_limit_reached_error(error_message):
            print("[ALERT] Modal deployment should be marked inactive (stopped/limit/error)!")
            print(f"[ACTION] Current deployment ID: {url_manager.current_deployment_id}")
            print("[ACTION] Marking current deployment as inactive in database...")
            
            success = url_manager.mark_deployment_inactive()
            print(f"[ACTION] Mark inactive result: {success}")
            
            # Invalidate the cache in app.py so it fetches fresh URL
            if success:
                print("[ACTION] Invalidating app.py cache...")
                try:
                    invalidate_response = requests.post(
                        f"{BACKEND_URL}/invalidate-cache",
                        timeout=5
                    )
                    if invalidate_response.status_code == 200:
                        print("[OK] Cache invalidation triggered successfully")
                    else:
                        print(f"[WARN] Cache invalidation returned {invalidate_response.status_code}")
                except Exception as cache_err:
                    print(f"[WARN] Failed to invalidate cache: {cache_err}")
            
            print("[ACTION] Getting next active deployment...")
            next_deployment = url_manager.get_active_deployment()
            if next_deployment:
                print(f"[OK] Next deployment ready: #{next_deployment['deployment_number']}")
                print("[INFO] Retrying ALL pending jobs with new deployment...")
                
                # STEP 3: URL Rotation Recovery - retry all pending jobs
                retry_all_pending_jobs()
            else:
                print("[ERROR] No active deployments available!")
            
            # DO NOT mark job as failed - leave it pending for retry
            print("[TERMINATE] Terminating current task without marking complete")
            print("[INFO] Job status remains unchanged for automatic retry")
            return
        
        # DO NOT mark job as failed for ANY error - leave it pending for retry
        print("[TERMINATE] Terminating current task without marking as failed")
        print("[INFO] Job remains in pending status for automatic retry")
        print(f"[DEBUG] Error was: {error_message}")
        return

def fetch_all_pending_jobs():
    """Fetch all pending jobs from the database"""
    try:
        print("ğŸ“¥ Fetching all pending jobs from database...")
        response = requests.get(
            f"{BACKEND_URL}/worker/pending-jobs",
            timeout=10,
            verify=VERIFY_SSL
        )
        
        if response.status_code == 200:
            data = response.json()
            jobs = data.get("jobs", [])
            print(f"âœ… Found {len(jobs)} pending job(s)")
            return jobs
        else:
            print(f"âš ï¸  Failed to fetch pending jobs: {response.status_code}")
            return []
    except Exception as e:
        print(f"âŒ Error fetching pending jobs: {e}")
        return []


def process_all_pending_jobs():
    """Process all pending jobs (backlog catch-up)"""
    print("\n" + "="*60)
    print("ğŸ”„ BACKLOG CATCH-UP: Processing pending jobs")
    print("="*60)
    
    pending_jobs = fetch_all_pending_jobs()
    
    if not pending_jobs:
        print("âœ… No pending jobs in backlog")
        print("="*60 + "\n")
        return
    
    print(f"ğŸ“‹ Processing {len(pending_jobs)} pending job(s)...\n")
    
    for idx, job in enumerate(pending_jobs, 1):
        job_id = job.get("job_id")
        job_type = job.get("job_type", "image")
        prompt = job.get("prompt", "")[:50]
        
        print(f"[{idx}/{len(pending_jobs)}] Processing job {job_id} ({job_type})")
        print(f"   Prompt: {prompt}...")
        
        try:
            # Get the appropriate URL based on job type
            url_manager = get_modal_url_manager()
            endpoint_url = url_manager.get_endpoint_url(job_type)
            
            if not endpoint_url:
                print(f"   âš ï¸  No active deployment available, skipping for now")
                continue
            
            # Process based on job type
            if job_type == "video":
                process_video_job(job, endpoint_url)
            else:
                process_image_job(job, endpoint_url)
            
            print(f"   âœ… Job {job_id} processed successfully\n")
        except Exception as e:
            print(f"   âš ï¸  Job {job_id} processing failed: {e}\n")
            # Don't stop - continue with next job
            continue
    
    print("="*60)
    print("âœ… Backlog catch-up completed")
    print("="*60 + "\n")


def retry_all_pending_jobs():
    """Retry all pending jobs after URL rotation (called after deployment marked inactive)"""
    print("\n" + "="*60)
    print("ğŸ”„ URL ROTATION RECOVERY: Retrying pending jobs with new deployment")
    print("="*60)
    
    # Small delay to allow cache invalidation to propagate
    time.sleep(1)
    
    # Process all pending jobs with new active deployment
    process_all_pending_jobs()


async def realtime_listener():
    """
    Async listener for NEW pending jobs via Supabase Realtime
    Subscribes to INSERT events on jobs table where status='pending'
    """
    from supabase import acreate_client
    
    try:
        # Create async Supabase client
        print("ğŸ”Œ Connecting to Supabase Realtime...")
        async_client = await acreate_client(SUPABASE_URL, SUPABASE_KEY)
        
        def handle_new_job(payload):
            """Callback for NEW job inserts (NON-BLOCKING)"""
            try:
                # Extract record from correct payload structure
                # Payload structure: {'data': {'type': 'INSERT', 'record': {...}}}
                data = payload.get("data", {})
                record = data.get("record", payload.get("new", payload.get("record", {})))
                
                if not record:
                    print(f"âš ï¸ No record found in payload: {payload}")
                    sys.stdout.flush()
                    return
                
                status = record.get("status")
                
                # Only process pending jobs
                if status != "pending":
                    return
                
                job_id = record.get("job_id")
                job_type = record.get("job_type", "image")
                
                print(f"\n{'='*70}")
                print(f"ğŸ”” NEW JOB RECEIVED VIA REALTIME!")
                print(f"{'='*70}")
                print(f"ğŸ“‹ Job ID: {job_id}")
                print(f"ğŸ“ Type: {job_type}")
                print(f"ğŸ¯ Status: {status}")
                print(f"ğŸ’¬ Prompt: {record.get('prompt', '')[:50]}...")
                print(f"{'='*70}\n")
                sys.stdout.flush()
                
                # Get appropriate endpoint URL
                url_manager = get_modal_url_manager()
                endpoint_url = url_manager.get_endpoint_url(job_type)
                
                if not endpoint_url:
                    print(f"   âš ï¸ No active deployment available")
                    sys.stdout.flush()
                    return
                
                # Process job in SEPARATE THREAD to avoid blocking the event loop
                # This allows the callback to return immediately and keep receiving events
                def process_in_thread():
                    try:
                        if job_type == "video":
                            process_video_job(record, endpoint_url)
                        else:
                            process_image_job(record, endpoint_url)
                        
                        print(f"\n{'='*70}")
                        print(f"âœ… REALTIME JOB COMPLETED: {job_id}")
                        print(f"{'='*70}\n")
                        sys.stdout.flush()
                    except Exception as thread_err:
                        print(f"\n{'='*70}")
                        print(f"âŒ ERROR PROCESSING JOB IN THREAD")
                        print(f"{'='*70}")
                        print(f"Error: {thread_err}")
                        import traceback
                        traceback.print_exc()
                        print(f"{'='*70}\n")
                        sys.stdout.flush()
                
                # Spawn thread and return immediately
                job_thread = threading.Thread(target=process_in_thread, daemon=True)
                job_thread.start()
                print(f"ğŸ§µ Job processing started in background thread")
                sys.stdout.flush()
                
            except Exception as e:
                print(f"\n{'='*70}")
                print(f"âŒ ERROR IN REALTIME CALLBACK")
                print(f"{'='*70}")
                print(f"Error: {e}")
                import traceback
                traceback.print_exc()
                print(f"{'='*70}\n")
                sys.stdout.flush()
        
        # Subscribe to ALL events on jobs table (same as app.py - proven to work)
        # Filter for pending jobs in the callback instead
        channel = async_client.channel("job-worker-pending")

        # Subscribe to postgres changes (AsyncRealtimeChannel has no on_subscribe)
        subscription_result = await channel.on_postgres_changes(
            event="*",  # ALL events (same as realtime_manager.py)
            schema="public",
            table="jobs",
            callback=handle_new_job
        ).subscribe()
        
        print(f"âœ… Subscription result: {subscription_result}")
        print("âœ… Subscribed to new pending jobs (Realtime active)")
        print()
        print("âš ï¸  NOTE: If events don't arrive, check Supabase Dashboard:")
        print("   Database â†’ Replication â†’ Enable Realtime for 'jobs' table")
        print()
        print("=" * 60)
        print("â³ LISTENING FOR NEW JOBS...")
        print("=" * 60)
        print()
        sys.stdout.flush()
        
        # Keep connection alive
        while True:
            await asyncio.sleep(1)
        
    except Exception as e:
        print(f"âŒ Realtime listener error: {e}")
        import traceback
        traceback.print_exc()


def run_async_listener():
    """Run async listener in background thread"""
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    loop.run_until_complete(realtime_listener())


def start_realtime():
    """Start job worker with Realtime subscription"""
    if not SUPABASE_URL or not SUPABASE_KEY:
        print("âŒ Missing Supabase credentials!")
        print("Set SUPABASE_URL and SUPABASE_ANON_KEY in .env")
        sys.exit(1)
    
    # STEP 1: Process backlog on startup (ONE-TIME CATCH-UP)
    print("\n" + "="*60)
    print("ğŸš€ WORKER STARTUP: Initial backlog catch-up")
    print("="*60)
    process_all_pending_jobs()
    print("âœ… Initial backlog processed!\n")
    
    print("=" * 60)
    print("âœ… JOB WORKER READY")
    print("=" * 60)
    print("ğŸ’¡ Switching to REALTIME mode (no more polling)")
    print("ğŸ’¡ Will receive instant notifications for new jobs")
    print("=" * 60)
    print()
    sys.stdout.flush()
    
    # STEP 2: Start Realtime listener in background thread
    realtime_thread = threading.Thread(target=run_async_listener, daemon=True)
    realtime_thread.start()
    
    # Keep main thread alive with heartbeat
    print("ğŸ’“ Worker heartbeat every 30 seconds...")
    print("   Press Ctrl+C to stop")
    print()
    sys.stdout.flush()
    
    try:
        from datetime import datetime
        last_heartbeat = time.time()
        while True:
            time.sleep(5)
            
            # Heartbeat every 30 seconds
            if time.time() - last_heartbeat >= 30:
                print(f"ğŸ’“ [{datetime.now().strftime('%H:%M:%S')}] Worker alive, listening for jobs...")
                sys.stdout.flush()
                last_heartbeat = time.time()
                
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ Worker stopped by user (Ctrl+C)")
        sys.exit(0)

if __name__ == "__main__":
    start_realtime()
